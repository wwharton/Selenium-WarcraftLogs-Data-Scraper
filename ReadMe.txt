This scraper captures meta data about World of Warcraft players from the website Warcraft Logs.

It's purpose is to capture, en masse, performance data about a list of players for auditing purposes.
This makes it easy to quickly sort players from "High Performance" to "Low Performance"

It uses Selenium and Beautiful Soup, and I chose to run it with a headless Chrome driver.

The player names to be queried were, in my case, generated by another script which I used to
    accomplish a similar task by calling on the website's API directly (also available in my Github)

Bottleneck:
Warcraft Logs, regrettably, throttles queries after 30 visits within ~1m
I investigated ways to work around this with IP/User Agent, but did not pursue implementation out of respect for the developer.




Too much information:
The ultimate purpose of this tool stems from a problem I encountered when capturing player data from the API.
Offered as a free service, the data aggregator Warcraft Logs does not permanently keep all their data.
Once performance metrics are calculated and logged, much of the raw data is dropped to conserve space.
I was interested in capturing exact data on less competitive (~50th percentile) players, whose raw data had been purged.
The problem is: only players in the 99th percentile of performance have their raw data saved for competitive purposes.
Thus, querying the API for these lower performing players delivers "estimated combat data" (since the raw data was purged).
This caused my API calculations for these players to vary as much as 5-10% off the rankings on the website.

This webscraper succeeds in capturing the exact performance of these "average" players,
    data and rankings which the website originally derived from the raw combat data.


